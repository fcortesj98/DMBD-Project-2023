{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Ego Analysis of the BitCoin Data"
   ],
   "metadata": {
    "id": "uldANhk0lLyj"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "xa7m3QsxlGyn",
    "ExecuteTime": {
     "end_time": "2024-02-01T15:51:42.354861Z",
     "start_time": "2024-02-01T15:51:41.761683Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p9/q_n4s9cj6m15m7f_8tvsd0380000gn/T/ipykernel_3952/1286680368.py:6: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import datetime\n",
    "\n",
    "# Data Wrangling\n",
    "import pandas as pd\n",
    "\n",
    "# Data VisualizationÂ´\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Network Analysis\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## General Analysis"
   ],
   "metadata": {
    "id": "ytzDr9c2wMCZ"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Get Graph\n",
    "Generate and print a graph reading the data from all csv files uploaded in the Google Drive"
   ],
   "metadata": {
    "id": "Cp4eaHpsljRD"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "path1 = '../data_tokens/2015-Q1/'\n",
    "path2 = '../data_tokens/2015-Q2/'\n",
    "path3 = '../data_tokens/2015-Q3/'\n",
    "path4 = '../data_tokens/2015-Q4/'\n",
    "path5 = '../data_tokens/2016-Q1/'\n",
    "path6 = '../data_tokens/2016-Q2/'\n",
    "path7 = '../data_tokens/2016-Q3/'\n",
    "path8 = '../data_tokens/2016-Q4/'\n",
    "path9 = '../data_tokens/2017-Q1/'\n",
    "path10 = '../data_tokens/2017-Q2/'\n",
    "\n",
    "files_15_Q1 = glob.glob(os.path.join(path1, \"*.csv\"))\n",
    "files_15_Q2 = glob.glob(os.path.join(path2, \"*.csv\"))\n",
    "files_15_Q3 = glob.glob(os.path.join(path3, \"*.csv\"))\n",
    "files_15_Q4 = glob.glob(os.path.join(path4, \"*.csv\"))\n",
    "files_16_Q1 = glob.glob(os.path.join(path5, \"*.csv\"))\n",
    "files_16_Q2 = glob.glob(os.path.join(path6, \"*.csv\"))\n",
    "files_16_Q3 = glob.glob(os.path.join(path7, \"*.csv\"))\n",
    "files_16_Q4 = glob.glob(os.path.join(path8, \"*.csv\"))\n",
    "files_17_Q1 = glob.glob(os.path.join(path9, \"*.csv\"))\n",
    "files_17_Q2 = glob.glob(os.path.join(path10, \"*.csv\"))\n",
    "\n",
    "df_15_Q1 = pd.concat((pd.read_csv(f) for f in files_15_Q1), ignore_index=True)\n",
    "df_15_Q2 = pd.concat((pd.read_csv(f) for f in files_15_Q2), ignore_index=True)\n",
    "df_15_Q3 = pd.concat((pd.read_csv(f) for f in files_15_Q3), ignore_index=True)\n",
    "df_15_Q4 = pd.concat((pd.read_csv(f) for f in files_15_Q4), ignore_index=True)\n",
    "df_16_Q1 = pd.concat((pd.read_csv(f) for f in files_16_Q1), ignore_index=True)\n",
    "df_16_Q2 = pd.concat((pd.read_csv(f) for f in files_16_Q2), ignore_index=True)\n",
    "df_16_Q3 = pd.concat((pd.read_csv(f) for f in files_16_Q3), ignore_index=True)\n",
    "df_16_Q4 = pd.concat((pd.read_csv(f) for f in files_16_Q4), ignore_index=True)\n",
    "df_17_Q1 = pd.concat((pd.read_csv(f) for f in files_17_Q1), ignore_index=True)\n",
    "df_17_Q2 = pd.concat((pd.read_csv(f) for f in files_17_Q2), ignore_index=True)"
   ],
   "metadata": {
    "id": "dUGqMDHQqb57",
    "ExecuteTime": {
     "end_time": "2024-02-01T15:51:46.435866Z",
     "start_time": "2024-02-01T15:51:44.592195Z"
    }
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "Graphtype = nx.Graph()\n",
    "# Use as normal Graph for Analysis\n",
    "G_15_Q1 = nx.from_pandas_edgelist(df_15_Q1, 'Source', 'Target', ['value', 'nb_transactions'], create_using=nx.Graph)\n",
    "G_15_Q2 = nx.from_pandas_edgelist(df_15_Q2, 'Source', 'Target', ['value', 'nb_transactions'], create_using=nx.Graph)\n",
    "G_15_Q3 = nx.from_pandas_edgelist(df_15_Q3, 'Source', 'Target', ['value', 'nb_transactions'], create_using=nx.Graph)\n",
    "G_15_Q4 = nx.from_pandas_edgelist(df_15_Q4, 'Source', 'Target', ['value', 'nb_transactions'], create_using=nx.Graph)\n",
    "G_16_Q1 = nx.from_pandas_edgelist(df_16_Q1, 'Source', 'Target', ['value', 'nb_transactions'], create_using=nx.Graph)\n",
    "G_16_Q2 = nx.from_pandas_edgelist(df_16_Q2, 'Source', 'Target', ['value', 'nb_transactions'], create_using=nx.Graph)\n",
    "G_16_Q3 = nx.from_pandas_edgelist(df_16_Q3, 'Source', 'Target', ['value', 'nb_transactions'], create_using=nx.Graph)\n",
    "G_16_Q4 = nx.from_pandas_edgelist(df_16_Q4, 'Source', 'Target', ['value', 'nb_transactions'], create_using=nx.Graph)\n",
    "G_17_Q1 = nx.from_pandas_edgelist(df_17_Q1, 'Source', 'Target', ['value', 'nb_transactions'], create_using=nx.Graph)\n",
    "G_17_Q2 = nx.from_pandas_edgelist(df_17_Q2, 'Source', 'Target', ['value', 'nb_transactions'], create_using=nx.Graph)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-01T15:51:55.228287Z",
     "start_time": "2024-02-01T15:51:47.087044Z"
    }
   },
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "graph_list = [#G_15_Q1, G_15_Q2, G_15_Q3, G_15_Q4, G_16_Q1, \n",
    "    G_16_Q2, G_16_Q3, G_16_Q4, G_17_Q1, G_17_Q2] "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-01T15:51:56.007522Z",
     "start_time": "2024-02-01T15:51:56.001915Z"
    }
   },
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Ego Analysis"
   ],
   "metadata": {
    "id": "YrffeXuzv7I5"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Extract Ego Node and display Ego Network"
   ],
   "metadata": {
    "id": "w702NqO4v9pS"
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " ***** 2016 - Q3 ***** \n",
      "i: 7\n",
      "Nodes: [0, 12, 2, 188, 11, 1, 2183, 56, 2210, 64]\n",
      "\n",
      " *** Node 0 ***\n",
      "\n",
      " *** Node 12 ***\n",
      "Number of Neighbors: 1440\n"
     ]
    }
   ],
   "source": [
    "i = 5\n",
    "graph_name = \"Error\"\n",
    "with open('results_ego_analysis.txt', 'w') as f:\n",
    "    f.write(\" ******************************************* \\n Ego Analysis \" + str(datetime.datetime.now()) + \" \\n ******************************************* \")\n",
    "    for G in graph_list:\n",
    "        if i == 0: \n",
    "            graph_name = \"2015 - Q1\"\n",
    "        if i == 1: \n",
    "            graph_name = \"2015 - Q2\"\n",
    "        if i == 2: \n",
    "            graph_name = \"2015 - Q3\"\n",
    "        if i == 3: \n",
    "            graph_name = \"2015 - Q4\"\n",
    "        if i == 4: \n",
    "            graph_name = \"2016 - Q1\"\n",
    "        if i == 5: \n",
    "            graph_name = \"2016 - Q2\"\n",
    "        if i == 6: \n",
    "            graph_name = \"2016 - Q3\"\n",
    "        if i == 7: \n",
    "            graph_name = \"2016 - Q4\"\n",
    "        if i == 8: \n",
    "            graph_name = \"2017 - Q1\"\n",
    "        if i == 9: \n",
    "            graph_name = \"2017 - Q2\"\n",
    "        print(\"\\n\\n ***** \" + graph_name + \" ***** \")\n",
    "        f.write(\"\\n\\n\\n ********  \" + graph_name + \" ******** \")\n",
    "        i = i + 1\n",
    "        print(\"i: \" + str(i))\n",
    "        # Calculate degree centrality for each node\n",
    "        degree_centrality = nx.degree_centrality(G)\n",
    "        # Sort nodes by degree centrality in descending order\n",
    "        sorted_nodes = sorted(degree_centrality, key=degree_centrality.get, reverse=True)\n",
    "        # Get the top 10 most connected nodes\n",
    "        top_10_nodes = sorted_nodes[:10]\n",
    "        print(\"Nodes: \" + str(top_10_nodes))\n",
    "        f.write(\"\\nNodes: \" + str(top_10_nodes))\n",
    "        for node in top_10_nodes:\n",
    "            if node == 0:\n",
    "                print(\"\\n *** Node \" + str(node) + \" ***\")\n",
    "            else: \n",
    "                print(\"\\n *** Node \" + str(node) + \" ***\")\n",
    "                f.write(\"\\n\\n ***** Node \" + str(node) + \" *****\")\n",
    "                ego_G = nx.ego_graph(G, node, center=True)\n",
    "                # Neighbors\n",
    "                neighbors = list(G.neighbors(node))\n",
    "                print(\"Number of Neighbors: \" + str(len(neighbors)))\n",
    "                f.write(\"\\n Number of Neighbors: \" + str(len(neighbors)))\n",
    "                \"\"\"\n",
    "                nx.draw(ego_G, with_labels=True, node_color='skyblue', font_size=8, font_color='black', edge_color='gray', width=1, edge_cmap=plt.cm.Blues)\n",
    "                plt.title(\"Neighbors of Node \" + str(node))\n",
    "                plt.savefig(\"../images/neighbors/neighbors_\" +  str(graph_name) + \"_\" + str(node) + \".png\", format='png')\n",
    "                plt.show()\n",
    "                \"\"\"\n",
    "                # Centrality\n",
    "                #centrality = nx.degree_centrality(ego_G)\n",
    "                #print(\"Centrality: \" + str(centrality))\n",
    "                #f.write(\"\\n\\nCentrality: \" + str(centrality))\n",
    "                \"\"\"\n",
    "                plt.hist(centrality, bins=50)\n",
    "                plt.xlabel(\"Label of Node\")\n",
    "                plt.ylabel(\"Centrality\")\n",
    "                plt.title(\"Centrality of Node \" + str(node))\n",
    "                plt.savefig(\"../images/centrality/centrality_\" +  str(graph_name) + \"_\" + str(node) + \".png\", format='png')\n",
    "                plt.show()\n",
    "                \"\"\"\n",
    "                # Betweenness\n",
    "                #betweenness = nx.betweenness_centrality(ego_G)\n",
    "                #print(\"\\n\\nBetweenness: \" + str(betweenness))\n",
    "                #f.write(\"\\n\\nBetweenness: \" + str(betweenness))\n",
    "                \"\"\"\n",
    "                plt.hist(betweenness, bins=50)\n",
    "                plt.xlabel(\"Label of Node\")\n",
    "                plt.ylabel(\"Betweenness\")\n",
    "                plt.title(\"Betweenness of Node \" + str(node))\n",
    "                plt.savefig(\"../images/betweenness/betweenness_\" +  str(graph_name) + \"_\" + str(node) + \".png\", format='png')\n",
    "                plt.show()\n",
    "                \"\"\"\n",
    "                # Eigenvector\n",
    "                #eigenvector = nx.eigenvector_centrality(ego_G)\n",
    "                #print(\"\\n\\nEigenvector: \" + str(eigenvector))\n",
    "                #f.write(\"\\n\\nEigenvector: \" + str(eigenvector))\n",
    "                \"\"\"\n",
    "                plt.hist(eigenvector, bins=50)\n",
    "                plt.xlabel(\"Label of Node\")\n",
    "                plt.ylabel(\"Eigenvector\")\n",
    "                plt.title(\"Eigenvector of Node \" + str(node))\n",
    "                plt.savefig(\"../images/eigenvector/eigenvector_\" +  str(graph_name) + \"_\" + str(node) + \".png\", format='png')\n",
    "                plt.show()\n",
    "                \"\"\"\n",
    "                # Closeness\n",
    "                #closeness = nx.closeness_centrality(ego_G)\n",
    "                #print(\"\\n\\nCloseness: \" + str(closeness))\n",
    "                #f.write(\"\\n\\nCloseness: \" + str(closeness) + \"\\n\")\n",
    "                \"\"\"\n",
    "                plt.hist(closeness, bins=50)\n",
    "                plt.xlabel(\"Label of Node\")\n",
    "                plt.ylabel(\"Closeness\")\n",
    "                plt.title(\"Closeness of Node \" + str(node))\n",
    "                plt.savefig(\"../images/closeness/closeness_\" +  str(graph_name) + \"_\" + str(node) + \".png\", format='png')\n",
    "                plt.show()\n",
    "                \"\"\"\n",
    "                # Cliques\n",
    "                cliques = list(nx.find_cliques(ego_G))\n",
    "                # Cliques\n",
    "                #j = 1\n",
    "                #for clique in cliques:\n",
    "                    #print(\"Clique \" + str(j) + \": \" + str(clique) + \", Length: \" + str(len(clique)))\n",
    "                    #f.write(\"\\nClique \" + str(j) + \": \" + str(clique) + \", Length: \" + str(len(clique)))\n",
    "                    #j += 1\n",
    "                print(\"Number of cliques: \" + str(len(cliques)))\n",
    "                f.write(\"\\n Number of cliques: \" + str(len(cliques)))\n",
    "                \"\"\"\n",
    "                clique_colors = [f'C{k}' for k in range(len(cliques))]\n",
    "                edge_colors = {edge: 'white' for edge in G.edges()}\n",
    "                for h, clique in enumerate(cliques):\n",
    "                    color = clique_colors[h]\n",
    "                    for edge in G.edges():\n",
    "                        if edge[0] in clique and edge[1] in clique:\n",
    "                            edge_colors[edge] = color\n",
    "                colors = [edge_colors[edge] for edge in G.edges()]\n",
    "                nx.draw(ego_G, with_labels=True, node_color='skyblue', font_size=8, font_color='black', edge_color=colors, width=1, edge_cmap=plt.cm.Blues)\n",
    "                plt.show()\n",
    "                \"\"\"\n",
    "                # Hubs\n",
    "                #hubs = nx.hits(ego_G)[0]\n",
    "                #print(\"\\n\\nHubs: \" + str(hubs))\n",
    "                #f.write(\"\\n\\nHubs: \" + str(hubs))\n",
    "                #print(\"\\n\\nAuthority: \" + str(authority))\n",
    "                #f.write(\"\\n\\nAuthority: \" + str(authority))\n",
    "                \"\"\"\n",
    "                node_sizes = []\n",
    "                for hub_node in hubs:\n",
    "                    node_size = hubs[hub_node]*10000\n",
    "                    node_sizes.append(node_size)\n",
    "                nx.draw(ego_G, with_labels=True, node_color='skyblue', node_size=node_sizes, font_size=8, font_color='black', edge_color='grey', width=1, edge_cmap=plt.cm.Blues)\n",
    "                plt.show()\n",
    "                \"\"\"\n",
    "                # Bridges\n",
    "                bridges = list(nx.bridges(ego_G))\n",
    "                #print(\"\\n\\nBridges: \" + str(bridges))\n",
    "                #f.write(\"\\n\\nBridges: \" + str(bridges))\n",
    "                print(\"Number of Bridges: \" + str(len(bridges)))\n",
    "                f.write(\"\\n Number of Bridges: \" + str(len(bridges)))\n",
    "                \"\"\"\n",
    "                options = ['r','gray']\n",
    "                colors = []\n",
    "                for j in ego_G.edges():\n",
    "                    if j in bridges:\n",
    "                        colors.append(options[0])\n",
    "                    else:\n",
    "                        colors.append(options[1])\n",
    "                nx.draw(ego_G, with_labels=True, node_color='skyblue', font_size=8, font_color='black', edge_color=colors, width=1, edge_cmap=plt.cm.Blues)\n",
    "                plt.show()\n",
    "                \"\"\"\n",
    "                # Periphery\n",
    "                periphery = list(nx.periphery(ego_G))\n",
    "                print(\"Number of periphery nodes: \" + str(len(periphery)))\n",
    "                f.write(\"\\n Number of periphery nodes: \" + str(len(periphery)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-01T15:51:59.731507Z"
    }
   },
   "execution_count": null
  }
 ]
}
